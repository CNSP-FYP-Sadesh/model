{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install numpy\n",
    "# %pip install pandas\n",
    "# ! pip install pot\n",
    "# %pip install gensim\n",
    "# %pip install scikit-learn\n",
    "# %pip install scipy\n",
    "# %pip install tqdm\n",
    "# %pip install prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import warnings\n",
    "import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "from scipy.spatial.distance import cdist, pdist, squareform, euclidean\n",
    "import ot \n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import ast\n",
    "import datetime\n",
    "from prophet import Prophet\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import recall_score, precision_score, mean_squared_error, r2_score, mean_absolute_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2500/2500 [01:11<00:00, 34.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train & test files are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2484/2484 [00:28<00:00, 87.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order file is created\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dtrans = pd.read_csv(\"./Dataset/Dunnhumby Dataset/transaction_data.csv\")\n",
    "dproducts = pd.read_csv(\"./Dataset/Dunnhumby Dataset/product.csv\")\n",
    "\n",
    "dproducts = dproducts[[\"PRODUCT_ID\",\"SUB_COMMODITY_DESC\"]]\n",
    "\n",
    "df = dtrans[[\"household_key\",\"BASKET_ID\",\"DAY\",\"PRODUCT_ID\",\"QUANTITY\",\"WEEK_NO\"]]\n",
    "\n",
    "df = pd.merge(dproducts,df, on='PRODUCT_ID', how='inner')\n",
    "\n",
    "df['user_id'] = df['household_key'].rank(method='dense').astype(int)\n",
    "\n",
    "df['order_id'] = df['BASKET_ID'].rank(method='dense').astype(int)\n",
    "\n",
    "df['product_id'] = df['PRODUCT_ID'].rank(method='dense').astype(int)\n",
    "\n",
    "df = df.drop([\"household_key\",\"BASKET_ID\",\"PRODUCT_ID\"],axis = 1)\n",
    "\n",
    "df.columns  = [\"commodity\",\"day\",'quantity',\"weekno\",\"user_id\",\"order_id\",\"product_id\"]\n",
    "\n",
    "dunnhumby_data_sorted = df.sort_values(by=['user_id', 'day'])\n",
    "dunnhumby_data_sorted\n",
    "\n",
    "train = dunnhumby_data_sorted.iloc[0:0]\n",
    "prior = dunnhumby_data_sorted.iloc[0:0]\n",
    "\n",
    "for i in tqdm(range(1, dunnhumby_data_sorted[\"user_id\"].nunique() + 1)):\n",
    "    latestOrder = dunnhumby_data_sorted[dunnhumby_data_sorted[\"user_id\"]==i].iloc[-1].copy()\n",
    "    priorOrders = dunnhumby_data_sorted[dunnhumby_data_sorted[\"user_id\"]==i].iloc[:-1].copy()\n",
    "    pri = priorOrders.iloc[0:0]\n",
    "\n",
    "#     if(priorOrders.order_id.nunique()<100):\n",
    "    for j in priorOrders.order_id.unique():\n",
    "        p = priorOrders[priorOrders[\"order_id\"]==j].copy()\n",
    "#             if(len(p)>50):\n",
    "#                 p = p.tail(50)\n",
    "#                 pri = pd.concat([p,pri], ignore_index=True)\n",
    "#             else:\n",
    "#                 pri = pd.concat([p,pri], ignore_index=True)\n",
    "        pri = pd.concat([p,pri], ignore_index=True)\n",
    "                \n",
    "    train.loc[len(train)] = latestOrder\n",
    "    prior = pd.concat([pri,prior], ignore_index=True)\n",
    "\n",
    "#     if i > 2000:\n",
    "#         print(\"stop at 1500\")\n",
    "#         break\n",
    "   \n",
    "print(\"Train & test files are created\")\n",
    "\n",
    "orders = pd.concat([train,prior],ignore_index=True)\n",
    "orders = orders.sort_values(by=['user_id', 'day'])\n",
    "\n",
    "orders['order_count'] = orders.groupby(['user_id', 'order_id'])['order_id'].transform('count')\n",
    "\n",
    "ordersClean = orders[orders['order_count'] > 5].copy()\n",
    "\n",
    "ordersClean = ordersClean.drop(columns=['order_count'])\n",
    "\n",
    "ordersClean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ordersClean = ordersClean.drop([\"commodity\",\"product_id\",\"quantity\"],axis =1)\n",
    "\n",
    "ordersClean = ordersClean.groupby('order_id').apply(lambda x: x.drop_duplicates(subset=['user_id'])).reset_index(drop=True)\n",
    "\n",
    "orderNew = ordersClean.iloc[0:0]\n",
    "\n",
    "for i in tqdm(range(1,ordersClean[\"user_id\"].nunique()+1)):\n",
    "    user = ordersClean[ordersClean[\"user_id\"]==i]\n",
    "#     if len(user) > 10:\n",
    "    user['days_since_prior_order'] = user['day'] - user['day'].shift(1)\n",
    "    user['order_number'] = range(1, len(user) + 1)\n",
    "\n",
    "    orderNew = pd.concat([user,orderNew], ignore_index=True)\n",
    "orderNew.to_csv(\"./Dataset/Customized Dunnhumby Dataset/orders.csv\")\n",
    "print(\"Order file is created\")\n",
    "\n",
    "common_order_ids = orderNew['order_id'].unique()\n",
    "\n",
    "train = train[train['order_id'].isin(common_order_ids)]\n",
    "prior = prior[prior['order_id'].isin(common_order_ids)]\n",
    "\n",
    "train.to_csv(\"./Dataset/Customized Dunnhumby Dataset/train.csv\")\n",
    "prior.to_csv(\"./Dataset/Customized Dunnhumby Dataset/prior.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commodity</th>\n",
       "      <th>day</th>\n",
       "      <th>quantity</th>\n",
       "      <th>weekno</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADULT CEREAL</td>\n",
       "      <td>706</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>274347</td>\n",
       "      <td>91366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DOG TREATS (SOFT TREATS)</td>\n",
       "      <td>668</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>258676</td>\n",
       "      <td>91352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FRZN BREADED PREPARED CHICK</td>\n",
       "      <td>703</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>3</td>\n",
       "      <td>272912</td>\n",
       "      <td>91245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHEESE: NATURAL PREPORTND</td>\n",
       "      <td>627</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>241699</td>\n",
       "      <td>60906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EASTER PLUSH</td>\n",
       "      <td>707</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>6</td>\n",
       "      <td>274793</td>\n",
       "      <td>92196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>GRANOLA BARS</td>\n",
       "      <td>706</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>2478</td>\n",
       "      <td>274377</td>\n",
       "      <td>91808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>ADULT CEREAL</td>\n",
       "      <td>706</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>2479</td>\n",
       "      <td>274280</td>\n",
       "      <td>91262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>TORTILLA/NACHO CHIPS</td>\n",
       "      <td>687</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>2480</td>\n",
       "      <td>266585</td>\n",
       "      <td>89183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>MACARONI DRY</td>\n",
       "      <td>682</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>2482</td>\n",
       "      <td>264724</td>\n",
       "      <td>89857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>ALL FAMILY CEREAL</td>\n",
       "      <td>708</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>2483</td>\n",
       "      <td>275055</td>\n",
       "      <td>90273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1358 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        commodity  day quantity weekno user_id order_id  \\\n",
       "0                    ADULT CEREAL  706        1    102       1   274347   \n",
       "1        DOG TREATS (SOFT TREATS)  668        1     96       2   258676   \n",
       "2     FRZN BREADED PREPARED CHICK  703        1    101       3   272912   \n",
       "3       CHEESE: NATURAL PREPORTND  627        2     90       4   241699   \n",
       "5                    EASTER PLUSH  707        2    102       6   274793   \n",
       "...                           ...  ...      ...    ...     ...      ...   \n",
       "2477                 GRANOLA BARS  706        1    102    2478   274377   \n",
       "2478                 ADULT CEREAL  706        1    102    2479   274280   \n",
       "2479         TORTILLA/NACHO CHIPS  687        1     99    2480   266585   \n",
       "2481                 MACARONI DRY  682        1     98    2482   264724   \n",
       "2482            ALL FAMILY CEREAL  708        2    102    2483   275055   \n",
       "\n",
       "     product_id  \n",
       "0         91366  \n",
       "1         91352  \n",
       "2         91245  \n",
       "3         60906  \n",
       "5         92196  \n",
       "...         ...  \n",
       "2477      91808  \n",
       "2478      91262  \n",
       "2479      89183  \n",
       "2481      89857  \n",
       "2482      90273  \n",
       "\n",
       "[1358 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commodity</th>\n",
       "      <th>day</th>\n",
       "      <th>quantity</th>\n",
       "      <th>weekno</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17784</th>\n",
       "      <td>HAMBURGER BUNS</td>\n",
       "      <td>703</td>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "      <td>2484</td>\n",
       "      <td>272941</td>\n",
       "      <td>6676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17785</th>\n",
       "      <td>FRUIT COCKTAIL FRUIT SALAD</td>\n",
       "      <td>703</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>2484</td>\n",
       "      <td>272941</td>\n",
       "      <td>9357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17786</th>\n",
       "      <td>BURRITOS</td>\n",
       "      <td>703</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>2484</td>\n",
       "      <td>272941</td>\n",
       "      <td>9680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17787</th>\n",
       "      <td>SOFT DRINKS 20PK&amp;24PK CAN CARB</td>\n",
       "      <td>703</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>2484</td>\n",
       "      <td>272941</td>\n",
       "      <td>11873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17788</th>\n",
       "      <td>BEERALEMALT LIQUORS</td>\n",
       "      <td>703</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>2484</td>\n",
       "      <td>272941</td>\n",
       "      <td>12646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593227</th>\n",
       "      <td>STICKS/ENROBED</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4766</td>\n",
       "      <td>60255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593228</th>\n",
       "      <td>CANDY BAGS-CHOCOCLATE</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4766</td>\n",
       "      <td>60427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593229</th>\n",
       "      <td>CANDY BOXED CHOCOLATES</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4766</td>\n",
       "      <td>60714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593230</th>\n",
       "      <td>PIES: FRUIT/NUT</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4766</td>\n",
       "      <td>60905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593231</th>\n",
       "      <td>LOAVE</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4766</td>\n",
       "      <td>62314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225778 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              commodity  day  quantity  weekno  user_id  \\\n",
       "17784                    HAMBURGER BUNS  703         2     101     2484   \n",
       "17785        FRUIT COCKTAIL FRUIT SALAD  703         1     101     2484   \n",
       "17786                          BURRITOS  703         4     101     2484   \n",
       "17787    SOFT DRINKS 20PK&24PK CAN CARB  703         1     101     2484   \n",
       "17788               BEERALEMALT LIQUORS  703         1     101     2484   \n",
       "...                                 ...  ...       ...     ...      ...   \n",
       "2593227                  STICKS/ENROBED   51         2       8        1   \n",
       "2593228           CANDY BAGS-CHOCOCLATE   51         1       8        1   \n",
       "2593229          CANDY BOXED CHOCOLATES   51         1       8        1   \n",
       "2593230                 PIES: FRUIT/NUT   51         1       8        1   \n",
       "2593231                           LOAVE   51         1       8        1   \n",
       "\n",
       "         order_id  product_id  \n",
       "17784      272941        6676  \n",
       "17785      272941        9357  \n",
       "17786      272941        9680  \n",
       "17787      272941       11873  \n",
       "17788      272941       12646  \n",
       "...           ...         ...  \n",
       "2593227      4766       60255  \n",
       "2593228      4766       60427  \n",
       "2593229      4766       60714  \n",
       "2593230      4766       60905  \n",
       "2593231      4766       62314  \n",
       "\n",
       "[2225778 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commodity</th>\n",
       "      <th>day</th>\n",
       "      <th>quantity</th>\n",
       "      <th>weekno</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADULT CEREAL</td>\n",
       "      <td>706</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>274347</td>\n",
       "      <td>91366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DOG TREATS (SOFT TREATS)</td>\n",
       "      <td>668</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>258676</td>\n",
       "      <td>91352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FRZN BREADED PREPARED CHICK</td>\n",
       "      <td>703</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>3</td>\n",
       "      <td>272912</td>\n",
       "      <td>91245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHEESE: NATURAL PREPORTND</td>\n",
       "      <td>627</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>241699</td>\n",
       "      <td>60906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EASTER PLUSH</td>\n",
       "      <td>707</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>6</td>\n",
       "      <td>274793</td>\n",
       "      <td>92196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>GRANOLA BARS</td>\n",
       "      <td>706</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>2478</td>\n",
       "      <td>274377</td>\n",
       "      <td>91808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>ADULT CEREAL</td>\n",
       "      <td>706</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>2479</td>\n",
       "      <td>274280</td>\n",
       "      <td>91262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>TORTILLA/NACHO CHIPS</td>\n",
       "      <td>687</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>2480</td>\n",
       "      <td>266585</td>\n",
       "      <td>89183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>MACARONI DRY</td>\n",
       "      <td>682</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>2482</td>\n",
       "      <td>264724</td>\n",
       "      <td>89857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>ALL FAMILY CEREAL</td>\n",
       "      <td>708</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>2483</td>\n",
       "      <td>275055</td>\n",
       "      <td>90273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1358 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        commodity  day quantity weekno user_id order_id  \\\n",
       "0                    ADULT CEREAL  706        1    102       1   274347   \n",
       "1        DOG TREATS (SOFT TREATS)  668        1     96       2   258676   \n",
       "2     FRZN BREADED PREPARED CHICK  703        1    101       3   272912   \n",
       "3       CHEESE: NATURAL PREPORTND  627        2     90       4   241699   \n",
       "5                    EASTER PLUSH  707        2    102       6   274793   \n",
       "...                           ...  ...      ...    ...     ...      ...   \n",
       "2477                 GRANOLA BARS  706        1    102    2478   274377   \n",
       "2478                 ADULT CEREAL  706        1    102    2479   274280   \n",
       "2479         TORTILLA/NACHO CHIPS  687        1     99    2480   266585   \n",
       "2481                 MACARONI DRY  682        1     98    2482   264724   \n",
       "2482            ALL FAMILY CEREAL  708        2    102    2483   275055   \n",
       "\n",
       "     product_id  \n",
       "0         91366  \n",
       "1         91352  \n",
       "2         91245  \n",
       "3         60906  \n",
       "5         92196  \n",
       "...         ...  \n",
       "2477      91808  \n",
       "2478      91262  \n",
       "2479      89183  \n",
       "2481      89857  \n",
       "2482      90273  \n",
       "\n",
       "[1358 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "base_date_str = \"20230101\"\n",
    "base_date = datetime.strptime(base_date_str, \"%Y%m%d\")\n",
    "orders[\"SHOP_DATE\"] = base_date + pd.to_timedelta(orders['day'], unit='D')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.to_csv(\"./Dataset/Customized Dunnhumby Dataset/combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commodity</th>\n",
       "      <th>day</th>\n",
       "      <th>quantity</th>\n",
       "      <th>weekno</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>order_count</th>\n",
       "      <th>SHOP_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2595702</th>\n",
       "      <td>SEMI-SOLID SALAD DRESSING MAY</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4766</td>\n",
       "      <td>6533</td>\n",
       "      <td>30</td>\n",
       "      <td>2023-02-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595703</th>\n",
       "      <td>SHREDDED CHEESE</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4766</td>\n",
       "      <td>7270</td>\n",
       "      <td>30</td>\n",
       "      <td>2023-02-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595704</th>\n",
       "      <td>EGGS - LARGE</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4766</td>\n",
       "      <td>8279</td>\n",
       "      <td>30</td>\n",
       "      <td>2023-02-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595705</th>\n",
       "      <td>MEAT: TURKEY BULK</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4766</td>\n",
       "      <td>8837</td>\n",
       "      <td>30</td>\n",
       "      <td>2023-02-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595706</th>\n",
       "      <td>TRADITIONAL</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4766</td>\n",
       "      <td>9648</td>\n",
       "      <td>30</td>\n",
       "      <td>2023-02-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>LAYER CAKE MIX</td>\n",
       "      <td>708</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>2500</td>\n",
       "      <td>275035</td>\n",
       "      <td>35884</td>\n",
       "      <td>21</td>\n",
       "      <td>2024-12-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>METAL BAKEWARE</td>\n",
       "      <td>708</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>2500</td>\n",
       "      <td>275035</td>\n",
       "      <td>38609</td>\n",
       "      <td>21</td>\n",
       "      <td>2024-12-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>CAULIFLOWER WHOLE</td>\n",
       "      <td>708</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>2500</td>\n",
       "      <td>275035</td>\n",
       "      <td>39466</td>\n",
       "      <td>21</td>\n",
       "      <td>2024-12-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>FRZN DINNER ROLLS</td>\n",
       "      <td>708</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>2500</td>\n",
       "      <td>275035</td>\n",
       "      <td>61761</td>\n",
       "      <td>21</td>\n",
       "      <td>2024-12-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>KIDS CEREAL</td>\n",
       "      <td>708</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>2500</td>\n",
       "      <td>275035</td>\n",
       "      <td>87210</td>\n",
       "      <td>21</td>\n",
       "      <td>2024-12-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2595732 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             commodity  day quantity weekno user_id order_id  \\\n",
       "2595702  SEMI-SOLID SALAD DRESSING MAY   51        1      8       1     4766   \n",
       "2595703                SHREDDED CHEESE   51        1      8       1     4766   \n",
       "2595704                   EGGS - LARGE   51        1      8       1     4766   \n",
       "2595705              MEAT: TURKEY BULK   51        1      8       1     4766   \n",
       "2595706                    TRADITIONAL   51        1      8       1     4766   \n",
       "...                                ...  ...      ...    ...     ...      ...   \n",
       "2515                    LAYER CAKE MIX  708        1    102    2500   275035   \n",
       "2516                    METAL BAKEWARE  708        1    102    2500   275035   \n",
       "2517                 CAULIFLOWER WHOLE  708        1    102    2500   275035   \n",
       "2518                 FRZN DINNER ROLLS  708        1    102    2500   275035   \n",
       "2519                       KIDS CEREAL  708        1    102    2500   275035   \n",
       "\n",
       "        product_id  order_count  SHOP_DATE  \n",
       "2595702       6533           30 2023-02-21  \n",
       "2595703       7270           30 2023-02-21  \n",
       "2595704       8279           30 2023-02-21  \n",
       "2595705       8837           30 2023-02-21  \n",
       "2595706       9648           30 2023-02-21  \n",
       "...            ...          ...        ...  \n",
       "2515         35884           21 2024-12-09  \n",
       "2516         38609           21 2024-12-09  \n",
       "2517         39466           21 2024-12-09  \n",
       "2518         61761           21 2024-12-09  \n",
       "2519         87210           21 2024-12-09  \n",
       "\n",
       "[2595732 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./Dataset/Customized Dunnhumby Dataset/product.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = \"./Dataset/Customized Dunnhumby Dataset/train.csv\"\n",
    "path_prior = \"./Dataset/Customized Dunnhumby Dataset/prior.csv\"\n",
    "path_products = \"./Dataset/Customized Dunnhumby Dataset/product.csv\"\n",
    "\n",
    "train_orders = pd.read_csv(path_train)\n",
    "prior_orders = pd.read_csv(path_prior)\n",
    "products = pd.read_csv(path_products)\n",
    "\n",
    "#Turn the product ID to a string\n",
    "#This is necessary because Gensim's Word2Vec expects sentences, so we have to resort to this dirty workaround\n",
    "train_orders[\"product_id\"] = train_orders[\"product_id\"].astype(str)\n",
    "prior_orders[\"product_id\"] = prior_orders[\"product_id\"].astype(str)\n",
    "train_products = train_orders.groupby(\"order_id\").apply(lambda order: order['product_id'].tolist())\n",
    "prior_products = prior_orders.groupby(\"order_id\").apply(lambda order: order['product_id'].tolist())\n",
    "\n",
    "#Create the final sentences\n",
    "sentences = prior_products._append(train_products).values\n",
    "\n",
    "#Train Word2Vec model\n",
    "model = gensim.models.Word2Vec(sentences, window=5, min_count=50, workers=4)\n",
    "\n",
    "model.save(\"product2vec.model\")\n",
    "model.wv.save_word2vec_format(\"product2vec.model.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasketConstructor(object):\n",
    "    '''\n",
    "        Group products into baskets(type: list)\n",
    "    '''\n",
    "    def __init__(self, raw_data_dir, cache_dir):\n",
    "        self.raw_data_dir = raw_data_dir\n",
    "        self.cache_dir = cache_dir\n",
    "    \n",
    "    def get_orders(self):\n",
    "        '''\n",
    "            get order context information\n",
    "        '''\n",
    "        orders = pd.read_csv(\"./Dataset/Customized Dunnhumby Dataset/orders.csv\")\n",
    "        orders = orders.fillna(0.0)\n",
    "        orders['days'] = orders.groupby(['user_id'])['days_since_prior_order'].cumsum()\n",
    "        orders['days_last'] = orders.groupby(['user_id'])['days'].transform(max)\n",
    "        orders['days_up_to_last'] = orders['days_last'] - orders['days']\n",
    "        del orders['days_last']\n",
    "        del orders['days']\n",
    "        return orders\n",
    "    \n",
    "    def get_orders_items(self, prior_or_train):\n",
    "        '''\n",
    "            get detailed information of prior or train orders \n",
    "        '''\n",
    "        orders_products = pd.read_csv(self.raw_data_dir + '%s.csv'%prior_or_train)\n",
    "        return orders_products\n",
    "    \n",
    "    def get_users_orders(self, prior_or_train):\n",
    "        '''\n",
    "            get users' prior detailed orders\n",
    "        '''\n",
    "        orders = self.get_orders()\n",
    "        order_products_prior = self.get_orders_items(prior_or_train)\n",
    "        users_orders = pd.merge(order_products_prior, orders[['user_id', 'order_id', 'order_number', 'days_up_to_last']], \n",
    "                    on = ['order_id', 'user_id'], how = 'left')\n",
    "        return users_orders\n",
    "    \n",
    "    def get_users_products(self, prior_or_train):\n",
    "        '''\n",
    "            get users' all purchased products\n",
    "        '''\n",
    "        users_products = self.get_users_orders(prior_or_train)[['user_id', 'product_id']].drop_duplicates()\n",
    "        users_products['product_id'] = users_products.product_id.astype(int)\n",
    "        users_products['user_id'] = users_products.user_id.astype(int)\n",
    "        users_products = users_products.groupby(['user_id'])['product_id'].apply(list).reset_index()\n",
    "        return users_products\n",
    "\n",
    "    def get_items(self, gran):\n",
    "        '''\n",
    "            get items' information\n",
    "            gran = [departments, aisles, products]\n",
    "        '''\n",
    "        items = pd.read_csv(self.raw_data_dir + '%s.csv'%gran)\n",
    "        return items\n",
    "    \n",
    "    def get_baskets(self, prior_or_train, reconstruct = False, none_idx = 49689):\n",
    "        '''\n",
    "            get users' baskets\n",
    "        '''\n",
    "        filepath = self.cache_dir + './basket_' + prior_or_train + '.pkl'\n",
    "        up = self.get_users_orders(prior_or_train).sort_values(['user_id', 'order_number', 'product_id'], ascending = True)\n",
    "        uid_oid = up[['user_id', 'order_number']].drop_duplicates()\n",
    "        up = up[['user_id', 'order_number', 'product_id']]\n",
    "        up_basket = up.groupby(['user_id', 'order_number'])['product_id'].apply(list).reset_index()\n",
    "        up_basket = pd.merge(uid_oid, up_basket, on = ['user_id', 'order_number'], how = 'left')\n",
    "#         for row in up_basket.loc[up_basket.product_id.isnull(), 'product_id'].index:\n",
    "#             up_basket.at[row, 'product_id'] = [none_idx]\n",
    "        up_basket = up_basket.sort_values(['user_id', 'order_number'], ascending = True).groupby(['user_id'])['product_id'].apply(list).reset_index()\n",
    "        up_basket.columns = ['user_id', 'basket']\n",
    "        return up_basket\n",
    "        \n",
    "    def get_item_history(self, prior_or_train, reconstruct = False, none_idx = 49689):\n",
    "        up = self.get_users_orders(prior_or_train).sort_values(['user_id', 'order_number', 'product_id'], ascending = True)\n",
    "        item_history = up.groupby(['user_id', 'order_number'])['product_id'].apply(list).reset_index()\n",
    "        item_history.loc[item_history.order_number == 1, 'product_id'] = item_history.loc[item_history.order_number == 1, 'product_id'] + [none_idx]\n",
    "        item_history = item_history.sort_values(['user_id', 'order_number'], ascending = True)\n",
    "        # accumulate \n",
    "        item_history['product_id'] = item_history.groupby(['user_id'])['product_id'].transform(pd.Series.cumsum)\n",
    "        # get unique item list\n",
    "        item_history['product_id'] = item_history['product_id'].apply(set).apply(list)\n",
    "        item_history = item_history.sort_values(['user_id', 'order_number'], ascending = True)\n",
    "        # shift each group to make it history\n",
    "        item_history['product_id'] = item_history.groupby(['user_id'])['product_id'].shift(1)\n",
    "        for row in item_history.loc[item_history.product_id.isnull(), 'product_id'].index:\n",
    "            item_history.at[row, 'product_id'] = [none_idx]\n",
    "        item_history = item_history.sort_values(['user_id', 'order_number'], ascending = True).groupby(['user_id'])['product_id'].apply(list).reset_index()\n",
    "        item_history.columns = ['user_id', 'history_items']\n",
    "        return item_history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingWrapper(object):\n",
    "    def __init__(self, type):\n",
    "        self.model = Word2Vec.load(\"product2vec.model\")\n",
    "\n",
    "        self.vocab_len = len(self.model.wv.index_to_key)\n",
    "        self.word2index = dict(zip([self.model.wv.index_to_key[i] for i in range(self.vocab_len)],\n",
    "                              [i for i in range(self.vocab_len)]))\n",
    "        self.word_index_df = pd.DataFrame(data=list(self.word2index.items()), columns=['product_id', 'emb_id'])\n",
    "        \n",
    "    def p2aisle_f(self, i):\n",
    "        return self.p2aisles[i]\n",
    "\n",
    "    def lookup_ind_f(self, i):\n",
    "        return self.word2index[i]\n",
    "\n",
    "    def get_closest_of_set(self, item_id, set_of_candidates):\n",
    "        vec_of_interest = self.model.wv.vectors[item_id]\n",
    "        closest = np.argmin([euclidean(vec_of_interest, self.model.wv.vectors[x]) for x in set_of_candidates])\n",
    "        return set_of_candidates[closest]\n",
    "    \n",
    "    def find_closest_from_preds(self, pred, candidates_l_l):\n",
    "        closest_from_history = []\n",
    "        for p in pred:\n",
    "            closest_from_history.append(self.get_closest_of_set(p, [x for seq in candidates_l_l for x in seq]))\n",
    "        return closest_from_history\n",
    "        \n",
    "    def basket_dist_REMD(self, baskets):\n",
    "        #Relaxed EMD as lower bound. It is basically a nearest neighborhood search to \n",
    "        #find the closest word in doc B for each word in doc A and then take sum of all minimum distances.    \n",
    "        basket1_vecs = self.model.wv.vectors[[x for x in baskets[0]]]\n",
    "        basket2_vecs = self.model.wv.vectors[[x for x in baskets[1]]]\n",
    "        \n",
    "        distance_matrix = cdist(basket1_vecs, basket2_vecs)\n",
    "        \n",
    "        return max(np.mean(np.min(distance_matrix, axis=0)),\n",
    "                   np.mean(np.min(distance_matrix, axis=1)))\n",
    "        \n",
    "    def basket_dist_EMD(self, baskets):\n",
    "        basket1 = baskets[0]\n",
    "        basket2 = baskets[1]\n",
    "        dictionary = np.unique(list(basket1) + list(basket2))\n",
    "        vocab_len_ = len(dictionary)\n",
    "        product2ind = dict(zip(dictionary, np.arange(vocab_len_)))\n",
    "\n",
    "        # Compute distance matrix.\n",
    "        dictionary_vecs = self.model.wv.vectors[[x for x in dictionary]]\n",
    "        distance_matrix = squareform(pdist(dictionary_vecs))\n",
    "\n",
    "        if np.sum(distance_matrix) == 0.0:\n",
    "            # `emd` gets stuck if the distance matrix contains only zeros.\n",
    "            return float('inf')\n",
    "\n",
    "        def nbow(document):\n",
    "            bow = np.zeros(vocab_len_, dtype=np.float32)\n",
    "            for d in document:\n",
    "                bow[product2ind[d]] += 1.\n",
    "            return bow / len(document)\n",
    "\n",
    "        # Compute nBOW representation of documents.\n",
    "        d1 = nbow(basket1)\n",
    "        d2 = nbow(basket2)\n",
    "\n",
    "        # Compute WMD.\n",
    "        return ot.emd2(d1, d2, distance_matrix)\n",
    "\n",
    "    def remove_products_wo_embeddings(self, all_baskets, user_ids):\n",
    "        all_baskets_filtered = []\n",
    "        new_user_ids = []\n",
    "        for (s, u_id) in zip(all_baskets, user_ids):\n",
    "            s_cp = []\n",
    "            for b in s:\n",
    "                b_cp = [x for x in b if x in self.model.wv.index_to_key]\n",
    "                if len(b_cp) > 0:\n",
    "                    s_cp.append(b_cp)\n",
    "            if len(s_cp) > 0:\n",
    "                all_baskets_filtered.append(s_cp)\n",
    "                new_user_ids.append(u_id)\n",
    "        return all_baskets_filtered, new_user_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_change(item, func):\n",
    "    if isinstance(item, list):\n",
    "        return [nested_change(x, func) for x in item]\n",
    "    return func(item)\n",
    "\n",
    "def remove_products_which_are_uncommon(all_baskets, user_ids, max_num=500):\n",
    "    print('Removing all but {} most common products'.format(max_num))\n",
    "    p = []\n",
    "    for s in all_baskets:\n",
    "        for b in s:\n",
    "            p.extend(b)\n",
    "    product_counter = Counter(p)\n",
    "    most_common_products = [x for x, _ in product_counter.most_common(max_num)]\n",
    "    new_user_ids = []\n",
    "    all_baskets_filtered = []\n",
    "    for (s, u_id) in zip(all_baskets, user_ids):\n",
    "        s_cp = []\n",
    "        for b in s:\n",
    "            b_cp = [x for x in b if x in most_common_products]\n",
    "            if len(b_cp) > 0:\n",
    "                s_cp.append(b_cp)\n",
    "        if len(s_cp) > 0:\n",
    "            new_user_ids.append(u_id)\n",
    "            all_baskets_filtered.append(s_cp)\n",
    "    return all_baskets_filtered, new_user_ids\n",
    "\n",
    "def remove_short_baskets(all_baskets, user_ids, l_b = 5, l_s = 10):\n",
    "    new_user_ids = []\n",
    "    all_baskets_filtered = []\n",
    "    for (s, u_id) in zip(all_baskets, user_ids):\n",
    "        s_cp = []\n",
    "        for b in s:\n",
    "            if len(b) > l_b:\n",
    "                s_cp.append(b)\n",
    "        if len(s_cp) > l_s:\n",
    "            new_user_ids.append(u_id)\n",
    "            all_baskets_filtered.append(s_cp)\n",
    "    return all_baskets_filtered, new_user_ids\n",
    "\n",
    "def convertType(item):\n",
    "    return [ast.literal_eval(x) for x in item]\n",
    "\n",
    "def split_data(all_baskets):\n",
    "    users = []\n",
    "    train_ub, test_ub = train_test_split(all_baskets, test_size=0.07, random_state=0)\n",
    "    train_ub, val_ub = train_test_split(train_ub, test_size=0.07, random_state=0)\n",
    "    \n",
    "    train_user_id = train_ub.user_id.values.tolist()\n",
    "    test_user_id = test_ub.user_id.values.tolist()\n",
    "    val_user_id = val_ub.user_id.values.tolist()\n",
    "    \n",
    "    users.append(train_user_id)\n",
    "    users.append(test_user_id)\n",
    "    users.append(val_user_id)\n",
    "    \n",
    "    train_ub = convertType(train_ub['basket'])\n",
    "    print(\"train done\")\n",
    "    \n",
    "    test_ub = convertType(test_ub['basket'])\n",
    "    print(\"test done\")\n",
    "    \n",
    "    val_ub = convertType(val_ub['basket'])\n",
    "    print(\"val done\")\n",
    "    test_ubC = [list(filter(lambda x: x is not None, sublist)) for sublist in test_ub]\n",
    "    val_ubC = [list(filter(lambda x: x is not None, sublist)) for sublist in val_ub]\n",
    "\n",
    "    test_ub_input = [x[:-1] for x in test_ubC]\n",
    "    test_ub_target = [x[-1] for x in test_ubC]\n",
    "    \n",
    "    val_ub_input = [x[:-1] for x in val_ubC]\n",
    "    val_ub_target = [x[-1] for x in val_ubC]\n",
    "    \n",
    "    return train_ub, val_ub_input, val_ub_target, test_ub_input, test_ub_target, val_user_id, test_user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnnDtw(object):    \n",
    "    def __init__(self, n_neighbors):\n",
    "        self.n_neighbors = n_neighbors  \n",
    "        self.length_to_consider = 10\n",
    "    \n",
    "    def _spring_dtw_distance(self, ts_a, ts_b, best_for_ts_a, d, d_lower_bound):\n",
    "        \"\"\"Returns the DTW subsequence similarity distance between two 2-D\n",
    "        timeseries numpy arrays.\n",
    "        \n",
    "        Following Subsequence Matching in Data Streams, Machiko Toyoda, Yasushi Sakurai\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        ts_a, ts_b : array of shape [n_samples, n_timepoints]\n",
    "            Two arrays containing n_samples of timeseries data\n",
    "            whose DTW distance between each sample of A and B\n",
    "            will be compared\n",
    "            \n",
    "        best_for_ts_a: list of length n_neighbors. The entries denote the\n",
    "            stortest distances found so far. This is for stopping the \n",
    "            calculation early utilizing a lower bound approximation.\n",
    "        \n",
    "        d : DistanceMetric object the distance measure used for market baskets A_i - B_j \n",
    "        in the DTW dynamic programming function\n",
    "        \n",
    "        d_lower_bound : Lower bound of DistanceMetric object the distance measure used for market baskets A_i - B_j \n",
    "        in the DTW dynamic programming function\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        DTW distance between A and B\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create cost matrix via broadcasting with large int\n",
    "        M, N = len(ts_a), len(ts_b)\n",
    "\n",
    "        #Compute REMD distances\n",
    "        REMD_gen = map(d_lower_bound, [(i,j) for i in ts_a for j in ts_b])\n",
    "        d_REMD_min = np.fromiter(REMD_gen, dtype=np.float32)\n",
    "\n",
    "        #Break here if there is no chance that this is the shortest\n",
    "        if np.sum(d_REMD_min[np.argpartition(d_REMD_min, M)][:M]) > max(best_for_ts_a):\n",
    "            return np.inf, ts_b[0]\n",
    "\n",
    "        cost = np.inf * np.ones((M, N))\n",
    "\n",
    "        #Compute all distances\n",
    "        d_mat = np.zeros((M,N))\n",
    "        for i in range(M):\n",
    "            for j in range(N):\n",
    "                d_mat[i,j] = d((ts_a[i], ts_b[j]))\n",
    "\n",
    "        # Initialize the first row and column\n",
    "        cost[0, 0] = d((ts_a[0], ts_b[0]))\n",
    "        for i in range(1, M):\n",
    "            cost[i, 0] = cost[i-1, 0] + d_mat[i, 0]\n",
    "\n",
    "        for j in range(1, N):\n",
    "            cost[0, j] = d_mat[0, j]\n",
    "            \n",
    "        # Populate rest of cost matrix within window\n",
    "        for i in range(1, M):\n",
    "            w = 1.\n",
    "            for j in range(1, N):\n",
    "                choices = cost[i-1, j-1], cost[i, j-1], cost[i-1, j]\n",
    "                cost[i, j] = min(choices) + w * d_mat[i,j]\n",
    "\n",
    "        min_idx = np.argmin(cost[-1,:-1])\n",
    "        # Return DTW distance, prediction for next basket\n",
    "        return cost[-1,min_idx], ts_b[min_idx + 1]\n",
    "  \n",
    "    def _dist_matrix(self, x, y, d, d_lower_bound):\n",
    "#         x_s = np.shape(x)\n",
    "#         y_s = np.shape(y)\n",
    "        x_s = [len(x)]\n",
    "        y_s = [len(y)]\n",
    "        dm = np.inf * np.ones((x_s[0], y_s[0])) \n",
    "        next_baskets = np.empty((x_s[0], y_s[0]), dtype=object)\n",
    "        \n",
    "        for i in tqdm(range(0, x_s[0])):\n",
    "            # Ensure all elements of x have the same length\n",
    "            max_length = max(len(seq) for seq in x[i])\n",
    "            x[i] = [np.array(seq)[-max_length:] for seq in x[i]]\n",
    "\n",
    "            best_dist = [np.inf] * max(self.n_neighbors)\n",
    "            for j in range(0, y_s[0]):\n",
    "                # Ensure all elements of y have the same length\n",
    "                max_length_y = max(len(seq_y) for seq_y in y[j])\n",
    "                y[j] = [np.array(seq_y)[-max_length_y:] for seq_y in y[j]]\n",
    "\n",
    "                dist, pred = self._spring_dtw_distance(x[i], y[j], best_dist, d, d_lower_bound)\n",
    "                if dist < np.max(best_dist):\n",
    "                    best_dist[np.argmax(best_dist)] = dist               \n",
    "                dm[i, j] = dist\n",
    "                next_baskets[i, j] = pred\n",
    "    \n",
    "        return dm, next_baskets\n",
    "        \n",
    "        \n",
    "    def predict(self, tr_d, te_d, d, d_lower_bound):\n",
    "        dm, predictions = self._dist_matrix(te_d, tr_d, d, d_lower_bound)\n",
    "        \n",
    "        preds_total_l = []\n",
    "        distances_total_l = []\n",
    "        for k in self.n_neighbors:\n",
    "            # Identify the k nearest neighbors\n",
    "            knn_idx = dm.argsort()[:, :k]\n",
    "            preds_k_l = []\n",
    "            distances_k_l = []\n",
    "                \n",
    "            for i in range(len(te_d)):\n",
    "                preds = [predictions[i][knn_idx[i][x]] for x in range(knn_idx.shape[1])]\n",
    "                distances = np.mean([dm[i][knn_idx[i][x]] for x in range(knn_idx.shape[1])])\n",
    "                pred_len = int(np.mean([len(te_d[i][x]) for x in range(len(te_d[i]))]))\n",
    "                preds = [x for x, y in Counter([n for s in preds for n in s]).most_common(pred_len)]                \n",
    "                preds_k_l.append(preds)\n",
    "                distances_k_l.append(distances)\n",
    "            preds_total_l.append(preds_k_l)\n",
    "            distances_total_l.append(distances_k_l)\n",
    "            \n",
    "        return preds_total_l, distances_total_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>weekno</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>order_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82</td>\n",
       "      <td>12</td>\n",
       "      <td>2484</td>\n",
       "      <td>11530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108</td>\n",
       "      <td>16</td>\n",
       "      <td>2484</td>\n",
       "      <td>20858</td>\n",
       "      <td>26</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112</td>\n",
       "      <td>17</td>\n",
       "      <td>2484</td>\n",
       "      <td>22542</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116</td>\n",
       "      <td>17</td>\n",
       "      <td>2484</td>\n",
       "      <td>24261</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125</td>\n",
       "      <td>19</td>\n",
       "      <td>2484</td>\n",
       "      <td>28266</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123801</th>\n",
       "      <td>687</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>266785</td>\n",
       "      <td>12</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123802</th>\n",
       "      <td>691</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>268408</td>\n",
       "      <td>4</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123803</th>\n",
       "      <td>695</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>270037</td>\n",
       "      <td>4</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123804</th>\n",
       "      <td>697</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>270827</td>\n",
       "      <td>2</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123805</th>\n",
       "      <td>706</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>274347</td>\n",
       "      <td>9</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123806 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        day weekno user_id order_id days_since_prior_order  order_number\n",
       "0        82     12    2484    11530                    NaN           1.0\n",
       "1       108     16    2484    20858                     26           2.0\n",
       "2       112     17    2484    22542                      4           3.0\n",
       "3       116     17    2484    24261                      4           4.0\n",
       "4       125     19    2484    28266                      9           5.0\n",
       "...     ...    ...     ...      ...                    ...           ...\n",
       "123801  687     99       1   266785                     12          62.0\n",
       "123802  691     99       1   268408                      4          63.0\n",
       "123803  695    100       1   270037                      4          64.0\n",
       "123804  697    100       1   270827                      2          65.0\n",
       "123805  706    102       1   274347                      9          66.0\n",
       "\n",
       "[123806 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orderNew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    df = pd.read_csv(\"./Dataset/Customized Dunnhumby Dataset/combined.csv\")\n",
    "    return df\n",
    "\n",
    "def preprocess_data(retail_dataframe, cust_list):\n",
    "    df = retail_dataframe[['SHOP_DATE', 'order_id', 'user_id', 'product_id', 'quantity']]\n",
    "    df = df[df['user_id'].isin(cust_list)]\n",
    "    df = df.dropna()\n",
    "    df['SHOP_DATE'] = df['SHOP_DATE'].astype(str)\n",
    "    df['user_id'] = df['user_id'].astype(str)\n",
    "    df['product_id'] = df['product_id'].astype(str)\n",
    "    df['Date'] = pd.to_datetime(df['SHOP_DATE'], format='%Y-%m-%d').dt.strftime('%Y/%m/%d')\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.groupby(['Date', 'order_id', 'user_id', 'product_id'])['quantity'].apply(sum).reset_index()\n",
    "    df = df[['Date', 'user_id', 'product_id', 'quantity']].rename({'Date': 'ds', 'quantity': 'y'}, axis='columns')\n",
    "    return df\n",
    "\n",
    "def predict(pred_df):\n",
    "    cust_list = pred_df['User'].tolist()\n",
    "    fullcsv_df = load_data()\n",
    "    \n",
    "    train_df = preprocess_data(fullcsv_df, cust_list)\n",
    "    FINAL_DF = pd.DataFrame()\n",
    "    \n",
    "    for cust_id in cust_list:\n",
    "        prod_list = pred_df.loc[pred_df['User'] == cust_id, 'product_id'].iloc[0]\n",
    "        def_new = train_df[train_df['user_id'] == str(cust_id)]\n",
    "        def_new = def_new[def_new['product_id'].isin(prod_list)]\n",
    "        split_group = def_new.groupby('product_id')\n",
    "        splits = [split_group.get_group(x) for x in split_group.groups]\n",
    "        \n",
    "        for p_df in splits:\n",
    "            productcode = p_df['product_id'].iloc[0]\n",
    "            \n",
    "            if(len(p_df) > 3):\n",
    "                product_df = p_df[['ds', 'y']]\n",
    "                last_date = product_df['ds'].max().strftime('%Y-%m-%d')\n",
    "                m = Prophet(interval_width=0.95)\n",
    "                m.fit(product_df)\n",
    "                future = m.make_future_dataframe(periods=1, freq='W', include_history=False)\n",
    "                forecast = m.predict(future)\n",
    "                forecast = forecast[['yhat', 'ds']]\n",
    "                forecast['user_id'] = cust_id\n",
    "                forecast['product_id'] = productcode\n",
    "                forecast = forecast.rename(columns={'yhat': 'quantity'})\n",
    "                \n",
    "                FINAL_DF = pd.concat([FINAL_DF, forecast], ignore_index=True)\n",
    "    return FINAL_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commodity</th>\n",
       "      <th>day</th>\n",
       "      <th>quantity</th>\n",
       "      <th>weekno</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>order_count</th>\n",
       "      <th>SHOP_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2595702</th>\n",
       "      <td>SEMI-SOLID SALAD DRESSING MAY</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4766</td>\n",
       "      <td>6533</td>\n",
       "      <td>30</td>\n",
       "      <td>2023-02-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595703</th>\n",
       "      <td>SHREDDED CHEESE</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4766</td>\n",
       "      <td>7270</td>\n",
       "      <td>30</td>\n",
       "      <td>2023-02-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595704</th>\n",
       "      <td>EGGS - LARGE</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4766</td>\n",
       "      <td>8279</td>\n",
       "      <td>30</td>\n",
       "      <td>2023-02-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595705</th>\n",
       "      <td>MEAT: TURKEY BULK</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4766</td>\n",
       "      <td>8837</td>\n",
       "      <td>30</td>\n",
       "      <td>2023-02-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595706</th>\n",
       "      <td>TRADITIONAL</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4766</td>\n",
       "      <td>9648</td>\n",
       "      <td>30</td>\n",
       "      <td>2023-02-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>LAYER CAKE MIX</td>\n",
       "      <td>708</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>2500</td>\n",
       "      <td>275035</td>\n",
       "      <td>35884</td>\n",
       "      <td>21</td>\n",
       "      <td>2024-12-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>METAL BAKEWARE</td>\n",
       "      <td>708</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>2500</td>\n",
       "      <td>275035</td>\n",
       "      <td>38609</td>\n",
       "      <td>21</td>\n",
       "      <td>2024-12-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>CAULIFLOWER WHOLE</td>\n",
       "      <td>708</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>2500</td>\n",
       "      <td>275035</td>\n",
       "      <td>39466</td>\n",
       "      <td>21</td>\n",
       "      <td>2024-12-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>FRZN DINNER ROLLS</td>\n",
       "      <td>708</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>2500</td>\n",
       "      <td>275035</td>\n",
       "      <td>61761</td>\n",
       "      <td>21</td>\n",
       "      <td>2024-12-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>KIDS CEREAL</td>\n",
       "      <td>708</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>2500</td>\n",
       "      <td>275035</td>\n",
       "      <td>87210</td>\n",
       "      <td>21</td>\n",
       "      <td>2024-12-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2595732 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             commodity  day quantity weekno user_id order_id  \\\n",
       "2595702  SEMI-SOLID SALAD DRESSING MAY   51        1      8       1     4766   \n",
       "2595703                SHREDDED CHEESE   51        1      8       1     4766   \n",
       "2595704                   EGGS - LARGE   51        1      8       1     4766   \n",
       "2595705              MEAT: TURKEY BULK   51        1      8       1     4766   \n",
       "2595706                    TRADITIONAL   51        1      8       1     4766   \n",
       "...                                ...  ...      ...    ...     ...      ...   \n",
       "2515                    LAYER CAKE MIX  708        1    102    2500   275035   \n",
       "2516                    METAL BAKEWARE  708        1    102    2500   275035   \n",
       "2517                 CAULIFLOWER WHOLE  708        1    102    2500   275035   \n",
       "2518                 FRZN DINNER ROLLS  708        1    102    2500   275035   \n",
       "2519                       KIDS CEREAL  708        1    102    2500   275035   \n",
       "\n",
       "        product_id  order_count  SHOP_DATE  \n",
       "2595702       6533           30 2023-02-21  \n",
       "2595703       7270           30 2023-02-21  \n",
       "2595704       8279           30 2023-02-21  \n",
       "2595705       8837           30 2023-02-21  \n",
       "2595706       9648           30 2023-02-21  \n",
       "...            ...          ...        ...  \n",
       "2515         35884           21 2024-12-09  \n",
       "2516         38609           21 2024-12-09  \n",
       "2517         39466           21 2024-12-09  \n",
       "2518         61761           21 2024-12-09  \n",
       "2519         87210           21 2024-12-09  \n",
       "\n",
       "[2595732 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_item_pred(val_pred_array, val_target_array):\n",
    "    jac_coef_list = []\n",
    "    for p_list, r_list in zip(val_pred_array, val_target_array):\n",
    "        p = len(list(set(p_list).intersection(r_list)))\n",
    "        q = len([i for i in p_list if i not in r_list])\n",
    "        r = len([i for i in r_list if i in p_list])\n",
    "        j = p/(p+q+r)\n",
    "        jac_coef_list.append(j)\n",
    "    jaccard_coefficient = sum(jac_coef_list) / len(jac_coef_list)\n",
    "    \n",
    "    multibinarizer = MultiLabelBinarizer()\n",
    "    \n",
    "    target_array = multibinarizer.fit(val_target_array).transform(val_target_array)\n",
    "    pred_array = multibinarizer.transform(val_pred_array)\n",
    "    \n",
    "    p = precision_score(target_array, pred_array, average='samples')\n",
    "    r = recall_score(target_array, pred_array, average='samples')\n",
    "    \n",
    "    f1_score = 2 * ((p*r)/(p+r))\n",
    "    \n",
    "    return jaccard_coefficient, f1_score\n",
    "\n",
    "def eval_quantity_pred(result_df):\n",
    "    df = pd.read_csv('./Dataset/Customized Dunnhumby Dataset/combined.csv', index_col=0)\n",
    "    df['Date'] = pd.to_datetime(df['SHOP_DATE'])\n",
    "    result_df_new = result_df\n",
    "    result_df_new['product_id'] = result_df_new['product_id'].astype(str)\n",
    "    user_list = list(set(result_df_new.user_id.to_list()))\n",
    "    df = df[df['user_id'].isin(user_list)]\n",
    "    df_fb = df[df.groupby('user_id')['Date'].transform('max') == df['Date']]\n",
    "    df_fb = df_fb.rename(columns={'quantity': 'actual_quantity'})\n",
    "    df_fb[\"product_id\"] = df_fb[\"product_id\"].astype(str)\n",
    "    final_df = pd.merge(result_df_new, df_fb, on=['user_id', 'product_id'])\n",
    "    final_df['bool'] = np.where((final_df['quantity'] == final_df['actual_quantity']), True, False)\n",
    "    \n",
    "    mse = mean_squared_error(final_df.actual_quantity, final_df.quantity)\n",
    "    r2_s = r2_score(final_df.actual_quantity, final_df.quantity)\n",
    "    mae = mean_absolute_error(final_df.actual_quantity, final_df.quantity)\n",
    "    rmse = sqrt(mean_squared_error(final_df.actual_quantity, final_df.quantity))\n",
    "    hit_count = final_df['bool'].value_counts()[True]\n",
    "    hit_precentage = hit_count/len(final_df)\n",
    "    \n",
    "    return mse, r2_s, mae, rmse, hit_precentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T06:56:33.000172Z",
     "iopub.status.busy": "2024-01-26T06:56:32.999733Z",
     "iopub.status.idle": "2024-01-26T06:56:33.038419Z",
     "shell.execute_reply": "2024-01-26T06:56:33.037334Z",
     "shell.execute_reply.started": "2024-01-26T06:56:33.000135Z"
    }
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    embedding_wrapper = EmbeddingWrapper('product')\n",
    "    bc = BasketConstructor('./Dataset/Customized Dunnhumby Dataset/', './Dataset/Customized Dunnhumby Dataset/')\n",
    "    ub_basket = bc.get_baskets('prior', reconstruct=False)\n",
    "    user_ids = ub_basket.user_id.values.tolist()\n",
    "    all_baskets = ub_basket.basket.values\n",
    "    all_baskets = nested_change(list(all_baskets), str)\n",
    "    all_baskets, user_ids = embedding_wrapper.remove_products_wo_embeddings(all_baskets, user_ids)\n",
    "    all_baskets, user_ids = remove_products_which_are_uncommon(all_baskets, user_ids)\n",
    "    all_baskets, user_ids = remove_short_baskets(all_baskets, user_ids)\n",
    "    all_baskets = nested_change(all_baskets, embedding_wrapper.lookup_ind_f)\n",
    "\n",
    "    max_length = max(len(basket) for basket in all_baskets)\n",
    "    all_baskets_padded = [basket + [] * (max_length - len(basket)) for basket in all_baskets]\n",
    "    all_baskets_df = pd.DataFrame(all_baskets_padded, columns=[f'item_{i}' for i in range(max_length)])\n",
    "    all_baskets_array = all_baskets_df.astype(str).agg(', '.join, axis=1)\n",
    "    all_baskets_df = pd.DataFrame(all_baskets_array, columns=['basket'])\n",
    "    all_baskets_df['user_id'] = user_ids\n",
    "\n",
    "\n",
    "    train_ub, val_ub_input, val_ub_target, test_ub_input, test_ub_target, val_user, test_user = split_data(all_baskets_df)\n",
    "    train_ub = [list(filter(lambda x: x is not None, sublist)) for sublist in train_ub]\n",
    "    val_ub_input = [list(filter(lambda x: x is not None, sublist)) for sublist in val_ub_input]\n",
    "\n",
    "\n",
    "    # Item prediction using KNN-DTW\n",
    "    knndtw = KnnDtw(n_neighbors=[5])\n",
    "    print(\"Predicting..\")\n",
    "    preds_all, distances = knndtw.predict(train_ub, val_ub_input, embedding_wrapper.basket_dist_EMD, \n",
    "                                          embedding_wrapper.basket_dist_REMD)\n",
    "\n",
    "    preds_all = preds_all\n",
    "    distances = distances[0]\n",
    "\n",
    "    final_pred_df = pd.DataFrame({'User': val_user, 'Pred_Basket': preds_all[0], 'distances': distances})\n",
    "    target_df = pd.DataFrame({'User': val_user, 'Basket': val_ub_target})\n",
    "\n",
    "    emd_df = embedding_wrapper.word_index_df\n",
    "    emd_df[\"product_id\"] = emd_df[\"product_id\"].astype(str)\n",
    "\n",
    "    final_pred__list = final_pred_df['Pred_Basket'].to_list()\n",
    "    final_target__list = target_df['Basket'].to_list()\n",
    "\n",
    "    final_pred_df['Basket'] = final_pred__list\n",
    "    target_df['Basket'] = final_target__list\n",
    "\n",
    "    new_df = final_pred_df.explode('Basket').reset_index(drop=True)\n",
    "    new_target_df = target_df.explode('Basket').reset_index(drop=True)\n",
    "\n",
    "    new_df['product_id'] = new_df['Basket'].map(emd_df.set_index('emb_id')['product_id'])\n",
    "    new_target_df['product_id'] = new_target_df['Basket'].map(emd_df.set_index('emb_id')['product_id'])\n",
    "    new_basket_df = new_df.groupby(['User', 'distances'])['product_id'].apply(list).reset_index()\n",
    "\n",
    "    result_df = predict(new_basket_df)\n",
    "    result_df['quantity'] = result_df['quantity'].apply(np.ceil).astype(int)\n",
    "    \n",
    "    jaccard_coefficient, f1_score = eval_item_pred(final_pred__list, val_ub_target)\n",
    "    mse, r2_s, mae, rmse, hit_percentage = eval_quantity_pred(result_df)\n",
    "\n",
    "    print(result_df, jaccard_coefficient, f1_score, mse, r2_s, mae, rmse, hit_percentage)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing all but 500 most common products\n",
      "train done\n",
      "test done\n",
      "val done\n",
      "Predicting..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 78/78 [2:29:20<00:00, 114.88s/it]\n",
      "20:05:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:05:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:05:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:08 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:06:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "20:06:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:06:13 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     quantity         ds  user_id product_id\n",
      "0           1 2024-12-08       22      34254\n",
      "1           1 2024-12-15       22      35571\n",
      "2           1 2024-12-01       41      32943\n",
      "3           1 2024-12-15       41      35571\n",
      "4           2 2024-09-29       99      22182\n",
      "..        ...        ...      ...        ...\n",
      "212         1 2024-10-13     2266      35571\n",
      "213         2 2024-12-01     2381      33679\n",
      "214         2 2024-12-15     2381      41169\n",
      "215         3 2024-12-01     2455      29652\n",
      "216         4 2024-07-21     2482      41169\n",
      "\n",
      "[217 rows x 4 columns] 0.10597890357505738 0.14084073880976486 0.5172413793103449 -2.6250000000000004 0.4482758620689655 0.7191949522280763 0.5862068965517241\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 408408,
     "sourceId": 782411,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
